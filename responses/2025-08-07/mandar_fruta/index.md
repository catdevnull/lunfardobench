# Evaluation Results for "mandar_fruta"

**Summary:**
- Total models evaluated: 36
- Correct responses: 23
- Accuracy: 63.9%

[📊 View CSV Results](./evaluation.csv)

## Results by Model

| Model | Result |
|-------|--------|
| x-ai-grok-3 | ✅ Correct |
| openai-gpt-4.1-nano | ✅ Correct |
| anthropic-claude-3-haiku | ✅ Correct |
| z-ai-glm-4.5-air | ✅ Correct |
| openai-gpt-4.1-mini | ✅ Correct |
| openai-gpt-5-chat | ✅ Correct |
| meta-llama-llama-4-maverick | ✅ Correct |
| openai-gpt-4o-mini | ✅ Correct |
| meta-llama-llama-3.1-70b-instruct | ✅ Correct |
| openai-gpt-5-mini | ✅ Correct |
| x-ai-grok-4 | ✅ Correct |
| deepseek-deepseek-chat-v3-0324 | ✅ Correct |
| google-gemini-2.5-flash | ✅ Correct |
| anthropic-claude-3.5-haiku | ✅ Correct |
| google-gemini-2.0-flash-001 | ✅ Correct |
| openai-gpt-oss-120b | ✅ Correct |
| google-gemini-pro-1.5 | ✅ Correct |
| qwen-qwen3-coder | ✅ Correct |
| z-ai-glm-4.5 | ✅ Correct |
| deepseek-deepseek-r1-0528 | ✅ Correct |
| microsoft-wizardlm-2-8x22b | ✅ Correct |
| moonshotai-kimi-k2 | ✅ Correct |
| openai-gpt-4o | ✅ Correct |
| x-ai-grok-3-mini | ❌ No Response |
| openai-gpt-5-nano | ❌ No Response |
| openai-gpt-oss-20b | ❌ No Response |
| mistralai-mistral-small-24b-instruct-2501 | ❌ Incorrect |
| meta-llama-llama-3.1-405b-instruct | ❌ Incorrect |
| qwen-qwen3-30b-a3b-instruct-2507 | ❌ Incorrect |
| z-ai-glm-4-32b | ❌ Incorrect |
| microsoft-phi-4-reasoning-plus | ❌ Incorrect |
| google-gemini-flash-1.5 | ❌ Incorrect |
| mistralai-mistral-small-3.2-24b-instruct | ❌ Incorrect |
| qwen-qwen3-235b-a22b-thinking-2507 | ❌ Incorrect |
| moonshotai-kimi-vl-a3b-thinking | ❌ Incorrect |
| meta-llama-llama-3.1-8b-instruct | ❌ Incorrect |

---
*Generated on: 2025-08-07T23:57:14.647Z*
